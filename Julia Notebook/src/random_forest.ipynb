{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99688cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # For plotting\n",
    "import numpy as np              # Linear algebra library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pwd\n",
    "expr_df = pd.read_csv(\"../metadata/length_and_depth.csv\")\n",
    "expr_df = expr_df.drop(\"nvar\", axis=1)\n",
    "expr_df = expr_df.rename(columns={\n",
    "    \"length\" : \"expr_length\",\n",
    "    \"depth\" : \"expr_depth\"\n",
    "})\n",
    "expr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b136ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.read_csv(\"../results/complete_dataset_as_of_nov6.csv\")\n",
    "complete_df = complete_df[complete_df[\"is_init_run\"] == 0]\n",
    "complete_df = complete_df.rename(columns={\"name\" : \"problem\"})\n",
    "df = complete_df.merge(\n",
    "    expr_df,\n",
    "    on = 'problem',\n",
    "    how = \"inner\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\"problem\", \"nvar\"]\n",
    "\n",
    "d = df[df[\"time\"].notna()].copy()\n",
    "d = d.sort_values(group_cols + [\"time\", \"mem\"], ascending=True)\n",
    "\n",
    "best_idx = d.groupby(group_cols)[\"time\"].idxmin()\n",
    "best_mem_df = d.loc[best_idx].reset_index(drop=True)\n",
    "best_mem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mem_map = d.loc[best_idx].set_index(group_cols)[\"mem\"]\n",
    "\n",
    "df = df.copy()\n",
    "df[\"best_problem_mem\"] = df.set_index(group_cols).index.map(best_mem_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique instances: one row per (problem, nvar)\n",
    "instances = df[[\"problem\", \"nvar\"]].drop_duplicates()\n",
    "\n",
    "# shuffle instances\n",
    "instances = instances.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "n = len(instances)\n",
    "n_train = int(0.7 * n)\n",
    "n_valid = int(0.15 * n)\n",
    "\n",
    "train_inst = instances.iloc[:n_train]\n",
    "valid_inst = instances.iloc[n_train:n_train + n_valid]\n",
    "test_inst  = instances.iloc[n_train + n_valid:]\n",
    "\n",
    "# assign rows to splits by (problem, nvar)\n",
    "train_df = df.merge(train_inst, on=[\"problem\", \"nvar\"], how=\"inner\").reset_index(drop=True)\n",
    "valid_df = df.merge(valid_inst, on=[\"problem\", \"nvar\"], how=\"inner\").reset_index(drop=True)\n",
    "test_df  = df.merge(test_inst,  on=[\"problem\", \"nvar\"], how=\"inner\").reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "feature_cols = [\"nvar\", \n",
    "                \"expr_length\", \n",
    "                \"expr_depth\", \n",
    "                \"init_eval_obj_time\", \n",
    "                \"init_eval_grad_time\",\n",
    "                \"mem\",\n",
    "                ]\n",
    "target_col = \"time\"\n",
    "\n",
    "X_train = train_df[feature_cols].to_numpy(dtype=float)\n",
    "X_valid = valid_df[feature_cols].to_numpy(dtype=float)\n",
    "X_test  = test_df[feature_cols].to_numpy(dtype=float)\n",
    "\n",
    "t_train = np.log1p(train_df[target_col].to_numpy(dtype=float))\n",
    "t_valid = np.log1p(valid_df[target_col].to_numpy(dtype=float))\n",
    "t_test  = np.log1p(test_df[target_col].to_numpy(dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392645a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "best_rf = None\n",
    "best_score = np.inf\n",
    "best_params = None\n",
    "\n",
    "random_state = 66\n",
    "\n",
    "for n_estimators in range(100, 200, 10):\n",
    "    for max_depth in [3, 5, 7, 9]:\n",
    "        for min_leaf in [1, 2, 5]:\n",
    "            rf = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_leaf=min_leaf,\n",
    "                random_state=66,\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            rf.fit(X_train, t_train)\n",
    "\n",
    "            pred_valid = rf.predict(X_valid)\n",
    "            mse_valid = mean_squared_error(t_valid, pred_valid)\n",
    "\n",
    "            if mse_valid < best_score:\n",
    "                best_score = mse_valid\n",
    "                best_rf = rf\n",
    "                best_params = (n_estimators, max_depth, min_leaf)\n",
    "                print(\n",
    "                        \"New best:\",\n",
    "                        \"n =\", n_estimators,\n",
    "                        \"depth =\", max_depth,\n",
    "                        \"min_leaf =\", min_leaf,\n",
    "                        \"mse =\", mse_valid,\n",
    "                    )\n",
    "            else:\n",
    "                print(\n",
    "                        \"n =\", n_estimators,\n",
    "                        \"depth =\", max_depth,\n",
    "                        \"min_leaf =\", min_leaf,\n",
    "                        \"mse =\", mse_valid,\n",
    "                    )\n",
    "\n",
    "print(\"Best validation MSE (forest):\", best_score)\n",
    "print(\"Best params (n_estimators, max_depth, min_leaf):\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "best_n, best_depth, best_min_leaf = best_params\n",
    "\n",
    "X_train_full = np.vstack([X_train, X_valid])\n",
    "t_train_full = np.concatenate([t_train, t_valid])\n",
    "y_train_full = np.log1p(t_train_full)\n",
    "\n",
    "final_rf = RandomForestRegressor(\n",
    "    n_estimators=best_n,\n",
    "    max_depth=best_depth,\n",
    "    min_samples_leaf=best_min_leaf,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "final_rf.fit(X_train_full, y_train_full)\n",
    "\n",
    "# predict on test in log1p space\n",
    "pred_test_log = final_rf.predict(X_test)\n",
    "\n",
    "# convert back to time\n",
    "pred_test_time = np.expm1(pred_test_log)\n",
    "\n",
    "test_mse = mean_squared_error(t_test, pred_test_time)\n",
    "test_mae = mean_absolute_error(t_test, pred_test_time)\n",
    "test_r2  = r2_score(t_test, pred_test_time)\n",
    "\n",
    "print(\"Test MSE (time):\", test_mse)\n",
    "print(\"Test MAE (time):\", test_mae)\n",
    "print(\"Test R^2 (time):\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d550eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in feature_cols if c != \"mem\"]\n",
    "X_test  = test_df[feature_cols].to_numpy(dtype=float)\n",
    "\n",
    "def choose_best_mem(model, x_problem, mem_candidates):\n",
    "    preds = []\n",
    "    for mem in mem_candidates:\n",
    "        x = np.concatenate([x_problem, [mem]])\n",
    "        preds.append((mem, model.predict(x.reshape(1, -1))[0]))\n",
    "    return min(preds, key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_estimators, best_max_depth, best_min_leaf = best_params\n",
    "\n",
    "X_train_full = np.vstack([X_train, X_valid])\n",
    "t_train_full = np.concatenate([t_train, t_valid])\n",
    "\n",
    "final_rf = RandomForestRegressor(\n",
    "    n_estimators=best_n_estimators,\n",
    "    max_depth=best_max_depth,\n",
    "    min_samples_leaf=best_min_leaf,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "final_rf.fit(X_train_full, t_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_candidates = list(range(1, 101))\n",
    "\n",
    "preds = []\n",
    "for x_problem in X_test:\n",
    "    best_mem_pred, pred_time = choose_best_mem(final_rf, x_problem, mem_candidates)\n",
    "    preds.append(best_mem_pred)\n",
    "    print(f\"Best mem for problem {x_problem} is {best_mem_pred} with predicted time {pred_time}\")\n",
    "\n",
    "preds = np.array(preds)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf5805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def choose_best_mem_vectorized(model, x_problem, mem_candidates):\n",
    "    \"\"\"\n",
    "    Given problem features (no mem) and a list/array of candidate mem values,\n",
    "    return (best_mem, best_predicted_time) by minimizing model-predicted time.\n",
    "    Assumes the model was trained with features ordered as [problem_features..., mem].\n",
    "    \"\"\"\n",
    "    mem_candidates = np.asarray(mem_candidates, dtype=float)\n",
    "\n",
    "    X = np.hstack([\n",
    "        np.repeat(x_problem.reshape(1, -1), len(mem_candidates), axis=0),\n",
    "        mem_candidates.reshape(-1, 1)\n",
    "    ])\n",
    "\n",
    "    y = model.predict(X)\n",
    "    j = int(np.argmin(y))\n",
    "    return int(mem_candidates[j]), float(y[j])\n",
    "\n",
    "mem_candidates = np.arange(1, 101)\n",
    "\n",
    "preds = []\n",
    "pred_times = []\n",
    "\n",
    "for x_problem in X_test:  # X_test must be problem features only (no mem)\n",
    "    best_mem_pred, pred_time = choose_best_mem_vectorized(final_rf, x_problem, mem_candidates)\n",
    "    preds.append(best_mem_pred)\n",
    "    pred_times.append(pred_time)\n",
    "    print(f\"Best mem for problem {x_problem} is {best_mem_pred} with predicted time {pred_time}\")\n",
    "\n",
    "preds = np.array(preds, dtype=int)\n",
    "pred_times = np.array(pred_times, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e56c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_score = np.mean(y_pred_test == X_test[\"best_problem_mem\"])\n",
    "\n",
    "test_mse = mean_squared_error(t_test, y_pred_test)\n",
    "test_mae = mean_absolute_error(t_test, y_pred_test)\n",
    "test_r2  = r2_score(t_test, y_pred_test)\n",
    "\n",
    "print(\"Random forest test MSE:\", test_mse)\n",
    "print(\"Random forest test MAE:\", test_mae)\n",
    "print(\"Random forest test R^2:\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35262e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_feature_cols = [c for c in feature_cols if c != \"mem\"]\n",
    "mem_candidates_global = np.sort(train_df[\"mem\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mem_selector(model, df_split):\n",
    "    rows = []\n",
    "\n",
    "    # treat (problem, nvar) as one instance\n",
    "    for (prob, nvar), group in df_split.groupby([\"problem\", \"nvar\"]):\n",
    "        mems_available = np.sort(group[\"mem\"].unique())\n",
    "        mem_candidates = [m for m in mem_candidates_global if m in mems_available]\n",
    "        if not mem_candidates:\n",
    "            continue\n",
    "\n",
    "        # build x_problem without mem\n",
    "        row0 = group.iloc[0]\n",
    "        x_problem = row0[problem_feature_cols].to_numpy(dtype=float)\n",
    "\n",
    "        # this is where you use choose_best_mem\n",
    "        mem_pred, _ = choose_best_mem(model, x_problem, mem_candidates)\n",
    "\n",
    "        # true best mem and time for this instance\n",
    "        best_row = group.loc[group[\"time\"].idxmin()]\n",
    "        mem_best = best_row[\"mem\"]\n",
    "        time_best = best_row[\"time\"]\n",
    "\n",
    "        # actual time if we use mem_pred\n",
    "        time_chosen = group.loc[group[\"mem\"] == mem_pred, \"time\"].min()\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"problem\": prob,\n",
    "                \"nvar\": nvar,\n",
    "                \"mem_pred\": mem_pred,\n",
    "                \"mem_best\": mem_best,\n",
    "                \"time_best\": time_best,\n",
    "                \"time_chosen\": time_chosen,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    res = pd.DataFrame(rows)\n",
    "    if len(res) == 0:\n",
    "        return res, float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    frac_exact = (res[\"mem_pred\"] == res[\"mem_best\"]).mean()\n",
    "    avg_ratio = (res[\"time_chosen\"] / res[\"time_best\"]).mean()\n",
    "    return res, frac_exact, avg_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d77a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_rf, frac_exact_rf, avg_ratio_rf = evaluate_mem_selector(final_rf, test_df)\n",
    "print(\"forest exact match fraction:\", frac_exact_rf)\n",
    "print(\"forest avg time_chosen / time_best:\", avg_ratio_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest mem selector evaluation\n",
    "# test_res_rf, frac_exact_rf, avg_ratio_rf = evaluate_mem_selector(final_rf, test_df)\n",
    "\n",
    "ratio_rf = test_res_rf[\"time_chosen\"] / test_res_rf[\"time_best\"]\n",
    "\n",
    "print(\"RF exact match fraction:\", frac_exact_rf)\n",
    "print(\"RF avg time_chosen / time_best:\", avg_ratio_rf)\n",
    "print(\"RF median time_chosen / time_best:\", ratio_rf.median())\n",
    "print(\"RF frac within 5%:\", (ratio_rf <= 1.05).mean())\n",
    "print(\"RF frac within 10%:\", (ratio_rf <= 1.10).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tree0 = final_rf.estimators_[0]\n",
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "tree.plot_tree(\n",
    "    rf_tree0,\n",
    "    feature_names=feature_cols,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    max_depth=3,\n",
    "    fontsize=8,\n",
    "    precision=6,\n",
    ")\n",
    "plt.title(\"Random Forest: tree 0 (top 3 levels)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "    rf_tree0,\n",
    "    max_depth=6,\n",
    "    out_file=None,               # return string instead of writing directly to file\n",
    "    feature_names=feature_cols,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    precision=6                  # <-- more decimal places\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10300d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "\n",
    "os.makedirs(\"../tree_plots\", exist_ok=True)\n",
    "\n",
    "tree_graph = Source(dot_data)\n",
    "pdf_path = tree_graph.render(\n",
    "    filename=\"random_forest\",    # base name\n",
    "    directory=\"../tree_plots\",\n",
    "    format=\"pdf\",\n",
    "    cleanup=True                     # delete intermediate .dot\n",
    ")\n",
    "print(\"PDF written to:\", pdf_path)\n",
    "tree_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10504e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf_importances = final_rf.feature_importances_\n",
    "indices_rf = np.argsort(rf_importances)[::-1]  \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(feature_cols)), rf_importances[indices_rf])\n",
    "plt.xticks(range(len(feature_cols)), [feature_cols[i] for i in indices_rf], rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.title(\"Random forest feature importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
